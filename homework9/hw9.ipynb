{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce69dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2707c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Outputs ---\n",
      "Name: output, Shape: dim {\n",
      "  dim_param: \"s77\"\n",
      "}\n",
      "dim {\n",
      "  dim_value: 1\n",
      "}\n",
      "\n",
      "\n",
      "--- Final Operations ---\n",
      "Op Type: Gemm, Output Name: ['linear']\n",
      "Op Type: Relu, Output Name: ['relu_1']\n",
      "Op Type: Gemm, Output Name: ['output']\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the model\n",
    "model = onnx.load(\"./hair_classifier_v1.onnx\")\n",
    "\n",
    "# Get the graph\n",
    "graph = model.graph\n",
    "\n",
    "# 1. Check declared outputs (gives you the name and shape)\n",
    "print(\"--- Model Outputs ---\")\n",
    "for output in graph.output:\n",
    "    print(f\"Name: {output.name}, Shape: {output.type.tensor_type.shape}\")\n",
    "\n",
    "# 2. Inspect the last few nodes to see the operations\n",
    "print(\"\\n--- Final Operations ---\")\n",
    "# We look at the last 3 nodes to see the flow\n",
    "for node in graph.node[-3:]:\n",
    "    print(f\"Op Type: {node.op_type}, Output Name: {node.output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809ecb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape after preparation: (200, 200, 3)\n",
      "First pixel RGB values: R=61, G=104, B=22\n",
      "\n",
      "ðŸŽ¯ ANSWER: First pixel R channel value = 61\n",
      "\n",
      "Data type: uint8\n",
      "Value range: [0, 255]\n",
      "\n",
      "With normalization:\n",
      "First pixel R channel (normalized) = 0.239216\n",
      "==================================================\n",
      "FIRST PIXEL ANALYSIS\n",
      "==================================================\n",
      "Original RGB: [61, 104, 22]\n",
      "Normalized RGB: [0.239216, 0.407843, 0.086275]\n",
      "\n",
      "ðŸŽ¯ First pixel R channel = 61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Download and prepare the image\n",
    "url = 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'\n",
    "\n",
    "# Download the image\n",
    "img = download_image(url)\n",
    "\n",
    "# Prepare the image with target size (299, 299) - typical for image classification models\n",
    "target_size = (200, 200)\n",
    "img_prepared = prepare_image(img, target_size)\n",
    "\n",
    "# Convert to numpy array\n",
    "img_array = np.array(img_prepared)\n",
    "\n",
    "# Check the first pixel's R channel value\n",
    "first_pixel_r_channel = img_array[0, 0, 0]\n",
    "\n",
    "print(f\"Image shape after preparation: {img_array.shape}\")\n",
    "print(f\"First pixel RGB values: R={img_array[0, 0, 0]}, G={img_array[0, 0, 1]}, B={img_array[0, 0, 2]}\")\n",
    "print(f\"\\nðŸŽ¯ ANSWER: First pixel R channel value = {first_pixel_r_channel}\")\n",
    "\n",
    "# Additional information\n",
    "print(f\"\\nData type: {img_array.dtype}\")\n",
    "print(f\"Value range: [{img_array.min()}, {img_array.max()}]\")\n",
    "\n",
    "# If the model expects normalized values (0-1 range)\n",
    "img_array_normalized = img_array / 255.0\n",
    "\n",
    "first_pixel_r_normalized = img_array_normalized[0, 0, 0]\n",
    "\n",
    "print(f\"\\nWith normalization:\")\n",
    "print(f\"First pixel R channel (normalized) = {first_pixel_r_normalized:.6f}\")\n",
    "\n",
    "# Complete analysis of the first pixel\n",
    "print(\"=\"*50)\n",
    "print(\"FIRST PIXEL ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Original values (0-255)\n",
    "print(f\"Original RGB: [{img_array[0, 0, 0]}, {img_array[0, 0, 1]}, {img_array[0, 0, 2]}]\")\n",
    "\n",
    "# Normalized values (0-1)\n",
    "print(f\"Normalized RGB: [{img_array_normalized[0, 0, 0]:.6f}, {img_array_normalized[0, 0, 1]:.6f}, {img_array_normalized[0, 0, 2]:.6f}]\")\n",
    "\n",
    "# Answer\n",
    "print(f\"\\nðŸŽ¯ First pixel R channel = {img_array[0, 0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d436c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL INFORMATION\n",
      "============================================================\n",
      "Input name: input\n",
      "Input shape: ['s77', 3, 200, 200]\n",
      "Input type: tensor(float)\n",
      "\n",
      "Output name: output\n",
      "Output shape: ['s77', 1]\n",
      "Output type: tensor(float)\n",
      "\n",
      "============================================================\n",
      "PREPARED INPUT\n",
      "============================================================\n",
      "Final input shape: (1, 3, 200, 200)\n",
      "Input dtype: float32\n",
      "Input range: [0.0000, 1.0000]\n",
      "\n",
      "============================================================\n",
      "MODEL OUTPUT\n",
      "============================================================\n",
      "Raw output shape: (1, 1)\n",
      "Raw output: [[1.9222327]]\n",
      "\n",
      "Probabilities: [1.]\n",
      "Predicted class: 0\n",
      "Confidence: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the ONNX model\n",
    "model_path = \"./hair_classifier_v1.onnx\"\n",
    "session = ort.InferenceSession(model_path)\n",
    "\n",
    "# Step 2: Get model input/output information\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Input information\n",
    "input_info = session.get_inputs()[0]\n",
    "print(f\"Input name: {input_info.name}\")\n",
    "print(f\"Input shape: {input_info.shape}\")\n",
    "print(f\"Input type: {input_info.type}\")\n",
    "\n",
    "# Output information\n",
    "output_info = session.get_outputs()[0]\n",
    "print(f\"\\nOutput name: {output_info.name}\")\n",
    "print(f\"Output shape: {output_info.shape}\")\n",
    "print(f\"Output type: {output_info.type}\")\n",
    "\n",
    "# Step 3: Prepare your image\n",
    "url = 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'\n",
    "img = download_image(url)\n",
    "\n",
    "# Use the target size from model input shape (usually [batch, channels, height, width])\n",
    "# For example, if input shape is [1, 3, 299, 299]\n",
    "target_size = (200, 200)  # Adjust based on your model\n",
    "img_prepared = prepare_image(img, target_size)\n",
    "\n",
    "# Step 4: Convert to numpy array and preprocess\n",
    "img_array = np.array(img_prepared, dtype=np.float32)\n",
    "\n",
    "# Normalize to [0, 1] range\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Transpose from (height, width, channels) to (channels, height, width)\n",
    "# This is required for most deep learning models\n",
    "img_array = img_array.transpose(2, 0, 1)\n",
    "\n",
    "# Add batch dimension: (channels, height, width) -> (batch, channels, height, width)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PREPARED INPUT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final input shape: {img_array.shape}\")\n",
    "print(f\"Input dtype: {img_array.dtype}\")\n",
    "print(f\"Input range: [{img_array.min():.4f}, {img_array.max():.4f}]\")\n",
    "\n",
    "# Step 5: Run inference\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "outputs = session.run([output_name], {input_name: img_array})\n",
    "\n",
    "# Step 6: Get and process the output\n",
    "prediction = outputs[0]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL OUTPUT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Raw output shape: {prediction.shape}\")\n",
    "print(f\"Raw output: {prediction}\")\n",
    "\n",
    "# For classification, apply softmax to get probabilities\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "if prediction.ndim > 1:\n",
    "    probabilities = softmax(prediction[0])\n",
    "else:\n",
    "    probabilities = softmax(prediction)\n",
    "\n",
    "predicted_class = np.argmax(probabilities)\n",
    "\n",
    "print(f\"\\nProbabilities: {probabilities}\")\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Confidence: {probabilities[predicted_class]:.4f}\")\n",
    "\n",
    "# If it's binary classification (2 classes)\n",
    "if len(probabilities) == 2:\n",
    "    print(f\"\\nClass 0 probability: {probabilities[0]:.4f}\")\n",
    "    print(f\"Class 1 probability: {probabilities[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b52683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ PREDICTION RESULT:\n",
      "Predicted class: 0\n",
      "Confidence: 1.0000\n",
      "All probabilities: [1.0]\n"
     ]
    }
   ],
   "source": [
    "def predict_with_onnx(model_path, image_url, target_size=(299, 299)):\n",
    "    \"\"\"\n",
    "    Complete pipeline for ONNX model inference\n",
    "    \n",
    "    Parameters:\n",
    "    model_path (str): Path to .onnx model\n",
    "    image_url (str): URL of the image\n",
    "    target_size (tuple): Target size for image (height, width)\n",
    "    \n",
    "    Returns:\n",
    "    dict: Prediction results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load model\n",
    "    session = ort.InferenceSession(model_path)\n",
    "    \n",
    "    # Download and prepare image\n",
    "    img = download_image(image_url)\n",
    "    img_prepared = prepare_image(img, target_size)\n",
    "    \n",
    "    # Convert to array and preprocess\n",
    "    img_array = np.array(img_prepared, dtype=np.float32)\n",
    "    img_array = img_array / 255.0  # Normalize\n",
    "    img_array = img_array.transpose(2, 0, 1)  # HWC -> CHW\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Run inference\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    outputs = session.run([output_name], {input_name: img_array})\n",
    "    \n",
    "    # Process output\n",
    "    prediction = outputs[0]\n",
    "    \n",
    "    # Apply softmax\n",
    "    def softmax(x):\n",
    "        exp_x = np.exp(x - np.max(x))\n",
    "        return exp_x / exp_x.sum()\n",
    "    \n",
    "    if prediction.ndim > 1:\n",
    "        probabilities = softmax(prediction[0])\n",
    "    else:\n",
    "        probabilities = softmax(prediction)\n",
    "    \n",
    "    predicted_class = np.argmax(probabilities)\n",
    "    \n",
    "    return {\n",
    "        \"predicted_class\": int(predicted_class),\n",
    "        \"probabilities\": probabilities.tolist(),\n",
    "        \"confidence\": float(probabilities[predicted_class]),\n",
    "        \"raw_output\": prediction.tolist()\n",
    "    }\n",
    "\n",
    "# Usage\n",
    "result = predict_with_onnx(\n",
    "    model_path=\"./hair_classifier_v1.onnx\",\n",
    "    image_url='https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg',\n",
    "    target_size=(200, 200)\n",
    ")\n",
    "\n",
    "print(\"ðŸŽ¯ PREDICTION RESULT:\")\n",
    "print(f\"Predicted class: {result['predicted_class']}\")\n",
    "print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "print(f\"All probabilities: {result['probabilities']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
